library(automodel)
library(automodel)
setwd("D:/Documents/uniWork/MA317/groupWork")
data = read.csv("Life_Expectancy_Data1.csv")
life_exp.r = autoModel("SP.DYN.LE00.IN", data)
?autoModel()
document()
library(devtools)
document()
install.packages("stringr", repos = "http://cran.us.r-project.org")
install.packages("rlang", repos = "http://cran.us.r-project.org")
install.packages("stringr", repos = "http://cran.us.r-project.org")
install.packages("rlang", repos = "http://cran.us.r-project.org")
document()
document()
document()
document()
document()
warnings()
document()
document()
warnings
warnings()
document()
document()
document()
document()
document()
document()
document()
library(automodel)
library(automodel)
setwd("D:/Documents/uniWork/MA317/groupWork")
setwd("D:/Documents/uniWork/MA317/groupWork")
data = read.csv("Life_Expectancy_Data1.csv")
?automodel()
?autoModel()
summary(data)
results = autoModel("SP.DYN.LE00.IN",data)
results = autoModel("SP.DYN.LE00.IN", data)
document()
graphics.off()  # clear all graphs
rm(list = ls()) # remove all files from your workspace
library(readr) #used to read the tab files
library(xtable) #used to output r tables in latex format
library(automodel) #the function made during this dissertation, all code is within 'automodel.R'
#We have some functions which are used to process the ghq data sperate from everything else
#This code can be found in 'ghq_functions.R'
source(paste(getwd(),"/rCode/ghq_functions.R",sep=""))
#We have some functions which are used to process the ghq data sperate from everything else
#This code can be found in 'ghq_functions.R'
source(paste(getwd(),"/R/ghq_functions.R",sep=""))
#getting the wave 2 data
w2income = read_table("rData/selected/b_income.tab") #Income and payment
w2indresp = read_table("rData/selected/b_indresp.tab") #All information from the individual questionnaires
#getting the wave 3 data
w3income = read_table("rData/selected/c_income.tab") #Income and payment
w3indresp = read_table("rData/selected/c_indresp.tab") #All information from the individual questionnaires
#getting Nurse visit mixed data
#'xindresp_ns.tab' is Wave 2 and 3 Nurse - individual respondents data
mixNurse = read_table(file = "rData/selected/xindresp_ns.tab")
#Blood sample from nurse visit, 2010-2011 collected, 2013 analyzed
mixBloodData = read_table(file = "rData/selected/xlabblood_ns.tab")
#re-code the NA values
w2income = recodeNA(w2income)
w2indresp = recodeNA(w2indresp)
w3income = recodeNA(w3income)
w3indresp = recodeNA(w3indresp)
mixNurse = recodeNA(mixNurse)
mixBloodData = recodeNA(mixBloodData)
#we have to remove the GHQ related variables from the nurse data to avoid duplicate predictor columns
#making sure we are only getting relevant columns with the function
names(select(mixNurse,contains("ghq")))
#removing the questions and making a new dataset for it
joinSurveyData = select(mixNurse,-contains("ghq"))
#first, we need to remove some wave 2 & 3 naming conventions to assist when merging
names(w2income) = str_replace(names(w2income),"b_","")
names(w2indresp) = str_replace(names(w2indresp),"b_","")
names(w3income) = str_replace(names(w3income),"c_","")
names(w3indresp) = str_replace(names(w3indresp),"c_","")
#Having a quick investigation into the differences in variables cross wave
names(w2indresp)[names(w2indresp) %in% names(w3indresp)]
length(names(w2indresp)[names(w2indresp) %in% names(w3indresp)]) #number of shared variables
length(names(w2indresp)[!names(w2indresp) %in% names(w3indresp)]) #number of variables in w2indresp not in w3indresp
length(names(w3indresp)[!names(w3indresp) %in% names(w2indresp)]) #number of variables in w3indresp not in w2indresp
#adding a wave column to the survey data for joining
w2indresp$wave = 2
w3indresp$wave = 3
#next we have to join the survey data and income data together per wave 2 and 3, this requires some SQL
#merge income with nurse visit data (Note this use of sqlTransform here)
w2Merge = merge(w2indresp,sqlTransform(w2income), by = "pidp")
#now doing the same for wave 3
w3Merge = merge(w3indresp,sqlTransform(w3income), by = "pidp")
#Preforming the same investigation but for our transformed data w2Merge, w3Merge
length(names(w2Merge)[names(w2Merge) %in% names(w3Merge)]) #number of shared variables (tells us that all the income data is measured the same cross wave)
length(names(w2Merge)[!names(w2Merge) %in% names(w3Merge)]) #number of variables in w2indresp not in w3indresp
length(names(w3Merge)[!names(w3Merge) %in% names(w2Merge)]) #number of variables in w3indresp not in w2indresp
#we can make a versions of the data which only includes the shared variables which we can analyze
w2Shared = w2Merge[,names(w2Merge)[names(w2Merge) %in% names(w3Merge)]]
w3Shared = w3Merge[,names(w2Merge)[names(w2Merge) %in% names(w3Merge)]]
#now to stack the two datasets/union them
wShared = rbind(w2Shared,w3Shared)
#Lastly, we can now make all the joins between the relevant wave data. We are only going to use INNER JOIN's
#(reason is because analyze as clusters, LEFT JOIN would leave NA's for alot, doesn't share fair comparison)
w2MergeNurse = merge(x = w2Merge, y = joinSurveyData, by = c("pidp","wave")) #w2Merge with nurse visit data
w2MergeNurseBlood = merge(x = w2MergeNurse, y = mixBloodData, by = c("pidp","wave")) #w2Merge with blood samples
w3MergeNurse = merge(x = w3Merge, y = joinSurveyData, by = c("pidp","wave")) #w3Merge with nurse visit data
w3MergeNurseBlood = merge(x = w3MergeNurse, y = mixBloodData, by = c("pidp","wave")) #w3Merge with blood samples
wSharedNurse = merge(x = wShared, y = joinSurveyData, by = c("pidp","wave")) #wShared with nurse visit data
wSharedNurseBlood = merge(x = wSharedNurse, y = mixBloodData, by = c("pidp","wave")) #wShared with blood samples
mixNurseBlood = merge(x = mixNurse, y = mixBloodData, by = c("pidp","wave")) #nurse and blood data
#to assist this calculation, we need some variables to hold to two GHQ columns
ghq1_dv = na.omit(w2indresp$scghq1_dv)
ghq2_dv = na.omit(w2indresp$scghq2_dv)
#amount of groups in the ghq score
grGHQ = length(unique(ghq2_dv))
grGHQ
#amount of total scores possible in ghq score
scGHQ = length(unique(ghq1_dv))
scGHQ
#estimate size of each group in ghq2
grSize = scGHQ / grGHQ
grSize
#how far we should look each side of the predicted values
grSide = grSize / 2
grSide
#to compare our prediction accuracy on this data, I want to compare to:
#randomly picking a GHQ score if all scores assumed equal
randomPickCh.g = 1/length(unique(ghq1_dv))
randomPickCh.g
#then the chance of always picking the most common score in scghq
mstComm.g = as.numeric(names(which(table(ghq1_dv) == max(table(ghq1_dv)))))
paste("Mode/most frequent score is:",mstComm.g)
modePickCh.g = max(table(ghq1_dv)) / length(ghq1_dv)
modePickCh.g
#The chance when randomly picking within a +- 1 range (so randomly picking 7 is correct if real is in (6,7,8))
randomRangeCh.g = ((3*37)-2)/(length(unique(ghq1_dv))*37)
randomRangeCh.g
#The chance of picking within the largest +- 1 range (which is 6,7,8)
rangePickCh.g = sum(table(ghq1_dv)[c(mstComm.g + 1, mstComm.g + 2, mstComm.g + 3)]) / length(ghq1_dv)
rangePickCh.g
w2indresp.rData = ghq_clean_move(w2indresp)
w2Merge.rData = ghq_clean_move(w2Merge)
w2MergeNurse.rData = ghq_clean_move(w2MergeNurse)
w2MergeNurseBlood.rData = ghq_clean_move(w2MergeNurseBlood)
w3indresp.rData = ghq_clean_move(w3indresp)
w3Merge.rData = ghq_clean_move(w3Merge)
w3MergeNurse.rData = ghq_clean_move(w3MergeNurse)
w3MergeNurseBlood.rData = ghq_clean_move(w3MergeNurseBlood)
wShared.rData = ghq_clean_move(wShared)
wSharedNurse.rData = ghq_clean_move(wSharedNurse)
wSharedNurseBlood.rData = ghq_clean_move(wSharedNurseBlood)
subset(mixNurse, subset = -c("ghq"))
subset = -c("ghq")
subset(mixNurse, -c("ghq"))
subset(mixNurse, select = -c("ghq"))
-c("ghq")
?subset()
mixNurse[,-c("ghq")]
library(dplyr) #the 'select()' function is used to extract some data outside of automodel
#we have to remove the GHQ related variables from the nurse data to avoid duplicate predictor columns
#making sure we are only getting relevant columns with the function
names(select(mixNurse,contains("ghq")))
#removing the questions and making a new dataset for it
joinSurveyData = select(mixNurse,-contains("ghq"))
#first, we need to remove some wave 2 & 3 naming conventions to assist when merging
names(w2income) = str_replace(names(w2income),"b_","")
names(w2indresp) = str_replace(names(w2indresp),"b_","")
names(w3income) = str_replace(names(w3income),"c_","")
names(w3indresp) = str_replace(names(w3indresp),"c_","")
#Having a quick investigation into the differences in variables cross wave
names(w2indresp)[names(w2indresp) %in% names(w3indresp)]
#first, we need to remove some wave 2 & 3 naming conventions to assist when merging
names(w2income) = str_replace(names(w2income),"b_","")
library(stringr) #package is used to clean variable names (str_replace)
#we have to remove the GHQ related variables from the nurse data to avoid duplicate predictor columns
#making sure we are only getting relevant columns with the function
names(select(mixNurse,contains("ghq")))
#removing the questions and making a new dataset for it
joinSurveyData = select(mixNurse,-contains("ghq"))
#first, we need to remove some wave 2 & 3 naming conventions to assist when merging
names(w2income) = str_replace(names(w2income),"b_","")
names(w2indresp) = str_replace(names(w2indresp),"b_","")
names(w3income) = str_replace(names(w3income),"c_","")
names(w3indresp) = str_replace(names(w3indresp),"c_","")
#Having a quick investigation into the differences in variables cross wave
names(w2indresp)[names(w2indresp) %in% names(w3indresp)]
length(names(w2indresp)[names(w2indresp) %in% names(w3indresp)]) #number of shared variables
length(names(w2indresp)[!names(w2indresp) %in% names(w3indresp)]) #number of variables in w2indresp not in w3indresp
length(names(w3indresp)[!names(w3indresp) %in% names(w2indresp)]) #number of variables in w3indresp not in w2indresp
#adding a wave column to the survey data for joining
w2indresp$wave = 2
w3indresp$wave = 3
#next we have to join the survey data and income data together per wave 2 and 3, this requires some SQL
#merge income with nurse visit data (Note this use of sqlTransform here)
w2Merge = merge(w2indresp,sqlTransform(w2income), by = "pidp")
#now doing the same for wave 3
w3Merge = merge(w3indresp,sqlTransform(w3income), by = "pidp")
#Preforming the same investigation but for our transformed data w2Merge, w3Merge
length(names(w2Merge)[names(w2Merge) %in% names(w3Merge)]) #number of shared variables (tells us that all the income data is measured the same cross wave)
length(names(w2Merge)[!names(w2Merge) %in% names(w3Merge)]) #number of variables in w2indresp not in w3indresp
length(names(w3Merge)[!names(w3Merge) %in% names(w2Merge)]) #number of variables in w3indresp not in w2indresp
#we can make a versions of the data which only includes the shared variables which we can analyze
w2Shared = w2Merge[,names(w2Merge)[names(w2Merge) %in% names(w3Merge)]]
w3Shared = w3Merge[,names(w2Merge)[names(w2Merge) %in% names(w3Merge)]]
#now to stack the two datasets/union them
wShared = rbind(w2Shared,w3Shared)
#Lastly, we can now make all the joins between the relevant wave data. We are only going to use INNER JOIN's
#(reason is because analyze as clusters, LEFT JOIN would leave NA's for alot, doesn't share fair comparison)
w2MergeNurse = merge(x = w2Merge, y = joinSurveyData, by = c("pidp","wave")) #w2Merge with nurse visit data
w2MergeNurseBlood = merge(x = w2MergeNurse, y = mixBloodData, by = c("pidp","wave")) #w2Merge with blood samples
w3MergeNurse = merge(x = w3Merge, y = joinSurveyData, by = c("pidp","wave")) #w3Merge with nurse visit data
w3MergeNurseBlood = merge(x = w3MergeNurse, y = mixBloodData, by = c("pidp","wave")) #w3Merge with blood samples
wSharedNurse = merge(x = wShared, y = joinSurveyData, by = c("pidp","wave")) #wShared with nurse visit data
wSharedNurseBlood = merge(x = wSharedNurse, y = mixBloodData, by = c("pidp","wave")) #wShared with blood samples
mixNurseBlood = merge(x = mixNurse, y = mixBloodData, by = c("pidp","wave")) #nurse and blood data
#to assist this calculation, we need some variables to hold to two GHQ columns
ghq1_dv = na.omit(w2indresp$scghq1_dv)
ghq2_dv = na.omit(w2indresp$scghq2_dv)
#amount of groups in the ghq score
grGHQ = length(unique(ghq2_dv))
grGHQ
#amount of total scores possible in ghq score
scGHQ = length(unique(ghq1_dv))
scGHQ
#estimate size of each group in ghq2
grSize = scGHQ / grGHQ
grSize
#how far we should look each side of the predicted values
grSide = grSize / 2
grSide
#to compare our prediction accuracy on this data, I want to compare to:
#randomly picking a GHQ score if all scores assumed equal
randomPickCh.g = 1/length(unique(ghq1_dv))
randomPickCh.g
#then the chance of always picking the most common score in scghq
mstComm.g = as.numeric(names(which(table(ghq1_dv) == max(table(ghq1_dv)))))
paste("Mode/most frequent score is:",mstComm.g)
modePickCh.g = max(table(ghq1_dv)) / length(ghq1_dv)
modePickCh.g
#The chance when randomly picking within a +- 1 range (so randomly picking 7 is correct if real is in (6,7,8))
randomRangeCh.g = ((3*37)-2)/(length(unique(ghq1_dv))*37)
randomRangeCh.g
#The chance of picking within the largest +- 1 range (which is 6,7,8)
rangePickCh.g = sum(table(ghq1_dv)[c(mstComm.g + 1, mstComm.g + 2, mstComm.g + 3)]) / length(ghq1_dv)
rangePickCh.g
#now let's investigate the distribution of the GHQ score and the correlations between the questions, we can use the 'ghq_analyze' function
#after we've analyzed, we then remove GHQ questions and move some variables so that we get the best results from the model maker function
#Then, we can run each version of the joined data though the function and review the results
####################################
#wave 2 all participants
####################################
ghq_analyze(w2indresp)
w2indresp.rData = ghq_clean_move(w2indresp)
w2Merge.rData = ghq_clean_move(w2Merge)
w2MergeNurse.rData = ghq_clean_move(w2MergeNurse)
w2MergeNurseBlood.rData = ghq_clean_move(w2MergeNurseBlood)
w3indresp.rData = ghq_clean_move(w3indresp)
w3Merge.rData = ghq_clean_move(w3Merge)
w3MergeNurse.rData = ghq_clean_move(w3MergeNurse)
w3MergeNurseBlood.rData = ghq_clean_move(w3MergeNurseBlood)
wShared.rData = ghq_clean_move(wShared)
wSharedNurse.rData = ghq_clean_move(wSharedNurse)
wSharedNurseBlood.rData = ghq_clean_move(wSharedNurseBlood)
mixNurse.rData = ghq_clean_move(mixNurse)
mixNurseBlood.rData = ghq_clean_move(mixNurseBlood)
graphics.off()  # clear all graphs
rm(list = ls()) # remove all files from your workspace
titanicdata = read.csv("rData/train.csv")
titanicdata = read.csv("rData/TitanicData/train.csv")
library(automodel)
detach("package:automodel", unload = TRUE)
library(automodel)
titainciData = read.csv("rData/TitanicData/test.csv")
library(automodel)
titanicData = read.csv("rData/TitanicData/test.csv")
titanic.r = autoModel("Survived",titanicData)
titanicData = read.csv("rData/TitanicData/train.csv")
library(automodel)
titanicData = read.csv("rData/TitanicData/train.csv")
titanic.r = autoModel("Survived",titanicData)
?autoModel()
titanic.r = autoModel("Survived",titanicData, naPercent = 0.5, clusterAmount = 5, corrConfLevel = 0.8,
vifSelectionLevel = 20, modelSigLevel = 0.99)
graphics.off()  # clear all graphs
rm(list = ls()) # remove all files from your workspace
library(readr) #used to read the tab files
library(xtable) #used to output r tables in latex format
library(dplyr) #the 'select()' function is used to extract some data outside of automodel
library(stringr) #package is used to clean variable names (str_replace)
library(automodel) #the function made during this dissertation, all code is within 'automodel.R'
#We have some functions which are used to process the ghq data sperate from everything else
#This code can be found in 'ghq_functions.R'
source(paste(getwd(),"../rCode/ghq_functions.R",sep=""))
#We have some functions which are used to process the ghq data sperate from everything else
#This code can be found in 'ghq_functions.R'
source(paste(getwd(),"../rCode/ghq_functions.R",sep=""))
#We have some functions which are used to process the ghq data sperate from everything else
#This code can be found in 'ghq_functions.R'
source(paste(getwd(),"/../rCode/ghq_functions.R",sep=""))
#We have some functions which are used to process the ghq data sperate from everything else
#This code can be found in 'ghq_functions.R'
source(paste(getwd(),"/../rCode/ghq_functions.R",sep=""))
#getting the wave 2 data
w2income = read_table("../rData/selected/b_income.tab") #Income and payment
graphics.off()  # clear all graphs
rm(list = ls()) # remove all files from your workspace
library(readr) #used to read the tab files
library(xtable) #used to output r tables in latex format
library(dplyr) #the 'select()' function is used to extract some data outside of automodel
library(stringr) #package is used to clean variable names (str_replace)
library(automodel) #the function made during this dissertation, all code is within 'automodel.R'
install.packages("automodel")
install.packages("automodel","/")
install_local("automodel")
install.packages("automodel", repos = NULL, type="source")
install.packages("/", repos = NULL, type="source")
document()
library(devtools)
document()
document()
document()
document()
document()
document()
document()
document()
document()
document()
document()
document()
document()
?lm()
document()
library(devtools)
document()
