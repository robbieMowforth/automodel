% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/automodel.R
\name{autoModel}
\alias{autoModel}
\title{autoModel}
\usage{
autoModel(
  predictVar,
  data,
  naPercent = 0.2,
  cartSplit = 20,
  impFlag = FALSE,
  randomSeed = NULL,
  catLevels = 15,
  obsPerLevel = 5,
  clusterAmount = ifelse(length(unique(data[[predictVar]])) <= catLevels,
    length(unique(data[[predictVar]])), catLevels),
  corrConfLevel = 0.8,
  PCAFlag = FALSE,
  pcPercent = 0.95,
  testPercent = 0.25,
  kNNCount = round(sqrt(nrow(data)), 0),
  vifSelectionLevel = 10,
  modelSigLevel = 0.95,
  elasticCount = 10
)
}
\arguments{
\item{predictVar}{The name of the variable that is to be predicted/the name of the dependent variable}

\item{data}{The data-set of all the predictor variables and the dependent variable}

\item{naPercent}{This is the percentage amount of NA values allowed in a predictor variable.
If the predictor variable have naPercent percent or more of their values as NA/missing, the predictor variable is removed}

\item{cartSplit}{The amount of observations needed for a new threshold/node to be generated in a CART model.
CART is used to impute missing values and to generate a prediction model of the data within the code.}

\item{impFlag}{Flag to tell the function if we are wanting to impute the missing values instead of preforming a list-wise deletion.
If TRUE, a single CART imputation is done to impute the missing values.}

\item{randomSeed}{To make results reproducible, we must set a random seed within the function.
randomSeed can be set to any integer in the range -2147483647 to 2147483647 (2147483647 is the maximum integer allowed in R).}

\item{catLevels}{Decides on how many unique values/levels  a variable needs to be considered as a factor/categorical variable when modelling.
If a variable has less than or equal to catLevels levels, the variable gets encoded as a factor.}

\item{obsPerLevel}{How many observations are needed of a level in a categorical/factor variable.
If the level in the variable has less than obsPerLevel observations, all observations of this level are removed from the data-set}

\item{clusterAmount}{Sets the amount of clusters/centroids to be used in K-Means modelling.
Our K-Means model has clusterAmount clusters.}

\item{corrConfLevel}{The cuttoff point of when a correlation between two predictor variables is deemed to large/ will cause multicolinearaity in a model.
If the absolute value of the correlation coefficient between two predictor variables is greater than corrConfLevel, these variables will be considered for deletion.}

\item{PCAFlag}{Flag that tells the automodel function to preform PCA on the data-set.
If TRUE, PCA using the co-variance matrix and eigenvalue decomposition is preformed.}

\item{pcPercent}{This sets the needed amount of variance explained by the reduced principal component (PC) data-set.
When preforming dimension reduction, we keep the smallest amount of PC's that describe pcPercent of the variance in the data-set.}

\item{testPercent}{The proportion of observations after transformation within the testing data.
When preforming our Train Test split on our data, we set testPercent percent of our observations as our testing data and 1 - testPercent as our training data.
Our training data must maintain variance in all predictor variables and therefore the splitting process iterates until a correct split can be found.
If randomSeed is set, it only evaluates the Train Test split associated with the seed once.
A user can set testPercent to -1 if only one observation should be tested.}

\item{kNNCount}{The number of neighbors that are considered for each test observation in the kNN model.
Each test observation considers kNNCount neighbors to predict the dependent variable for the observation.}

\item{vifSelectionLevel}{We will be removing variables from the Ordinary Linear Regression model in order of their VIF score until all variables have a VIF score equal to or below vifSelectionLevel.}

\item{modelSigLevel}{To refine our Ordinary Linear Regression Model we remove variables based on their statistical significance, we use modelSigLevel to decide the minimum confidence level that each variable in the model needs to satisfy.
Each model needs to be considered significant at the modelSigLevel confidence level.}

\item{elasticCount}{When fitting our elastic net models, we need to fit models for different values of alpha (which takes values between 0 and 1).
elasticCount decides how many different values of alpha we try and the different values are incremented equally based on the value of elasticCount}
}
\description{
autoModel will attempt to model a variable from a given data-set using various different analytical techniques.
    It includes various cleaning & transforming procedures, K-Means model, kNN model, CART model, Ordinary Linear Regression Model,
        Elastic Net Regression Model.
}
\examples{
\dontrun{
#reading in an example csv as our data
data = read.csv("data.csv")

#running the autoModel function and setting the results to the variable 'data.results'
data.results = autoModel(predictVar = "Variable", data = data)
}
}
